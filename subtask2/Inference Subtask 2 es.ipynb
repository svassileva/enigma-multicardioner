{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1RXA3_zObUkl",
    "outputId": "41533b0a-3871-4ceb-ee93-4f4e9fe6350c"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from transformers import pipeline\n",
    "from transformers import AutoModelForTokenClassification\n",
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "import evaluate\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "tqdm.pandas()\n",
    "metric = evaluate.load('seqeval')\n",
    "map = {0: \"O\", 1: \"B-FARMACO\", 2: \"I-FARMACO\"}\n",
    "reverse_map = {'O':0, 'B-FARMACO': 1, 'I-FARMACO': 2}\n",
    "tokenizer_kwargs = {'padding': True, 'truncation':True, 'max_length':512}\n",
    "\n",
    "task = \"ner\"\n",
    "#base_model = 'aaaksenova/xlmr_medical'\n",
    "#output_path = 'output/models'\n",
    "#model_checkpoint = f\"aaaksenova/xlmr_drug_classifier\"\n",
    "num_labels = 3\n",
    "target_label = 'FARMACO'\n",
    "\n",
    "#aaaksenova/xlmr_medical - for just xlmr\n",
    "#aaaksenova/xlmr_drug_classifier + aaaksenova/xlmr_medical for filtering + xlmr\n",
    "#Spanish: aaaksenova/SpanishRoberta_multicardioner , \n",
    "#English: aaaksenova/BioLinkBert_multicardioner , \n",
    "#Italian: aaaksenova/SpanishRoberta_it_medprocner\n",
    "MODEL_CLASS = \"aaaksenova/xlmr_drug_classifier\"\n",
    "MODEL_NER = \"aaaksenova/xlmr_medical\" #\"aaaksenova/xlmr_medical\"\n",
    "use_filtering = True\n",
    "test_name = 'test' #dev\n",
    "lang = 'es'\n",
    "\n",
    "model_name = MODEL_NER[MODEL_NER.index('/')+1:]\n",
    "sentences_file = f'data/{test_name}_sentences.tsv'\n",
    "result_file = f'output/multicardioner_track2_{test_name}_{lang}_predictions_{model_name}_{use_filtering}.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'output/multicardioner_track2_test_es_predictions_xlmr_medical_True.tsv'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>batch_number</th>\n",
       "      <th>batch_start</th>\n",
       "      <th>text</th>\n",
       "      <th>lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>multicardioner_test+bg_1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Setting: primary care (PC).\\n</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>multicardioner_test+bg_1</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>Reason for consultation: 26-year-old woman who...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>multicardioner_test+bg_1</td>\n",
       "      <td>3</td>\n",
       "      <td>132</td>\n",
       "      <td>She had been seen at the PC emergency centre f...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>multicardioner_test+bg_1</td>\n",
       "      <td>4</td>\n",
       "      <td>197</td>\n",
       "      <td>She explained abdominal pain of 2 weeks' evolu...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>multicardioner_test+bg_1</td>\n",
       "      <td>5</td>\n",
       "      <td>333</td>\n",
       "      <td>Clinical history: personal history of no inter...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   filename  batch_number  batch_start  \\\n",
       "0  multicardioner_test+bg_1             1            0   \n",
       "1  multicardioner_test+bg_1             2           28   \n",
       "2  multicardioner_test+bg_1             3          132   \n",
       "3  multicardioner_test+bg_1             4          197   \n",
       "4  multicardioner_test+bg_1             5          333   \n",
       "\n",
       "                                                text lang  \n",
       "0                      Setting: primary care (PC).\\n   en  \n",
       "1  Reason for consultation: 26-year-old woman who...   en  \n",
       "2  She had been seen at the PC emergency centre f...   en  \n",
       "3  She explained abdominal pain of 2 weeks' evolu...   en  \n",
       "4  Clinical history: personal history of no inter...   en  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev_sentences = pd.read_csv(sentences_file, sep='\\t', keep_default_na=False)\n",
    "df_dev_sentences.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "TOKENIZATION_REGEX = re.compile(r\"([0-9\\w]+|[^0-9\\w])\", re.UNICODE) # â€™ - es, ' - en, ' - it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    original_token_offsets = []\n",
    "\n",
    "    offset = 0\n",
    "    new_offset = 0\n",
    "    nonspace_token_seen = False\n",
    "\n",
    "    tokens = [t for t in TOKENIZATION_REGEX.split(text) if t]\n",
    "    for t in tokens:\n",
    "        if not t.isspace():\n",
    "            original_token_offsets.append([offset, offset + len(t), t, new_offset, new_offset + len(t)])\n",
    "            nonspace_token_seen = True\n",
    "            new_offset += len(t) + 1\n",
    "        offset += len(t)\n",
    "        \n",
    "\n",
    "    tokenized_sentence = ' '.join([l[2] for l in original_token_offsets])\n",
    "\n",
    "    # store original token offsets\n",
    "    # pass the tokenized string for prediction\n",
    "    return tokenized_sentence, original_token_offsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sylvia/.local/lib/python3.10/site-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "classifier = pipeline(task=\"text-classification\", model=MODEL_CLASS, device='cuda')\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NER)\n",
    "model = AutoModelForTokenClassification.from_pretrained(MODEL_NER).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.model_max_length = 512\n",
    "ner_pipe = pipeline('ner', model=model, tokenizer=tokenizer, aggregation_strategy=\"simple\", stride=0, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'entity_group': 'FARMACO',\n",
       "  'score': 0.9957895,\n",
       "  'word': 'Cefazolin2g',\n",
       "  'start': 0,\n",
       "  'end': 11},\n",
       " {'entity_group': 'FARMACO',\n",
       "  'score': 0.9987437,\n",
       "  'word': 'gentamicin',\n",
       "  'start': 23,\n",
       "  'end': 33},\n",
       " {'entity_group': 'FARMACO',\n",
       "  'score': 0.99871254,\n",
       "  'word': 'rifampicin',\n",
       "  'start': 49,\n",
       "  'end': 59}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_pipe('Cefazolin2g c/8 hs iv; gentamicin 3mg/kg/day iv; rifampicin 600 mg c/12 hsvo.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "RjIURpjUvxLW"
   },
   "outputs": [],
   "source": [
    "# group annotations around a clinical procedure mention, based on the annotation label\n",
    "def group_annotations_strict(annotations):\n",
    "    groups = []\n",
    "    i = 0\n",
    "    while i < len(annotations):\n",
    "        if annotations[i]['entity_group'] == 'LABEL_0':\n",
    "            i += 1\n",
    "            continue\n",
    "\n",
    "        group = [] # for the strict strategy, a group is a B (or many Bs), followed by 1 or more Is\n",
    "        if annotations[i]['entity_group'] == 'LABEL_1':\n",
    "            group.append(annotations[i])\n",
    "            i += 1\n",
    "\n",
    "            while (i < len(annotations) and annotations[i]['entity_group'] == 'LABEL_1'):\n",
    "                group.append(annotations[i])\n",
    "                i += 1\n",
    "\n",
    "            while (i < len(annotations) and annotations[i]['entity_group'] == 'LABEL_2'):\n",
    "                group.append(annotations[i])\n",
    "                i += 1\n",
    "\n",
    "            groups.append(group)\n",
    "        else:\n",
    "            i+=1\n",
    "            continue\n",
    "\n",
    "    return groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "SsntbSAryqAn"
   },
   "outputs": [],
   "source": [
    "# merge grouped annotations to form a complete entity mention\n",
    "def merge_annotation_group_entries(annotation_group, sentence):\n",
    "    start = annotation_group[0]['start']\n",
    "    end = annotation_group[len(annotation_group) - 1]['end']\n",
    "    text = sentence[start:end]\n",
    "    return {'start': start, 'end': end, 'text': text}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "8f574bI6qEwE"
   },
   "outputs": [],
   "source": [
    "def get_mentions(sentence):\n",
    "    if use_filtering:\n",
    "        out = classifier(sentence, **tokenizer_kwargs)\n",
    "    #print(out[0]['label'] == 'ent')\n",
    "    if not use_filtering or out[0]['label'] == \"ent\":\n",
    "        ner_result = ner_pipe(sentence)\n",
    "        return [{'start': mention['start'], 'end': mention['end'], 'text': mention['word']} for mention in ner_result]\n",
    "        #annotation_groups = group_annotations_strict(ner_result)        \n",
    "        #return [merge_annotation_group_entries(group, sentence) for group in annotation_groups]\n",
    "    else:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_original_mention_offset(mentions, sentence, original_token_offsets, original_sentence, filename, batch_start):\n",
    "    original_mention_offsets = []\n",
    "    current_offset_idx = 0 \n",
    "    for mention in mentions:\n",
    "        start = mention['start']\n",
    "        end = mention['end']\n",
    "        \n",
    "        original_start = -1\n",
    "        original_end = -1\n",
    "        while current_offset_idx < len(original_token_offsets):\n",
    "            token = original_token_offsets[current_offset_idx]\n",
    "            \n",
    "            if token[3] <= start:\n",
    "                original_start = token[0]\n",
    "            \n",
    "            if token[4] >= end:\n",
    "                original_end = token[1]\n",
    "                break\n",
    "            \n",
    "            current_offset_idx += 1\n",
    "\n",
    "        sentence_no_spaces = sentence[start:end].replace(' ', '')\n",
    "        original_sentence_no_spaces = original_sentence[original_start:original_end].replace(' ', '')\n",
    "        # check whether the detected span is contained in the original\n",
    "        if sentence_no_spaces != original_sentence_no_spaces and not(sentence_no_spaces in original_sentence_no_spaces):\n",
    "            print('potential offset issue ', filename, sentence[start:end], original_sentence[original_start:original_end])\n",
    "        if original_start == -1 or original_end == -1:\n",
    "            print('mention not found ', filename, mention)\n",
    "            \n",
    "        original_mention_offsets.append({\n",
    "            'filename': filename, \n",
    "            'start_span':original_start+batch_start, \n",
    "            'end_span':original_end+batch_start, \n",
    "            'text': original_sentence[original_start:original_end]\n",
    "        })\n",
    "    \n",
    "    return original_mention_offsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Treatment was started with piperacillin tazobactam 4.5g iv every 8h (after taking blood cultures) for 4 days.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Treatment was started with piperacillin tazobactam 4 . 5g iv every 8h ( after taking blood cultures ) for 4 days .'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_sentence, original_token_offsets = tokenize(text)\n",
    "tokenized_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'entity_group': 'FARMACO',\n",
       "  'score': 0.9985007,\n",
       "  'word': 'piperacillin tazobactam',\n",
       "  'start': 27,\n",
       "  'end': 50}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_pipe(tokenized_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lb43SpEHQsI9",
    "outputId": "40405391-c271-4057-ba9f-457c8d2f8528"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'start': 27, 'end': 50, 'text': 'piperacillin tazobactam'}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mentions = get_mentions(tokenized_sentence)\n",
    "mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'filename': 'filename',\n",
       "  'start_span': 37,\n",
       "  'end_span': 60,\n",
       "  'text': 'piperacillin tazobactam'}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_original_mention_offset(mentions, tokenized_sentence, original_token_offsets, text, 'filename', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mention_spans(doc, mentions):\n",
    "    spans = []\n",
    "    current_offset_idx = 0 \n",
    "    for mention in mentions:\n",
    "        start = mention['start']\n",
    "        end = mention['end']\n",
    "        \n",
    "        span_start = -1\n",
    "        span_end = -1\n",
    "        while current_offset_idx < len(doc):\n",
    "            token = doc[current_offset_idx]\n",
    "            \n",
    "            if token.idx <= start:\n",
    "                span_start = token.idx\n",
    "            \n",
    "            if token.idx + len(token) >= end:\n",
    "                span_end = token.idx + len(token)\n",
    "                break\n",
    "            \n",
    "            current_offset_idx += 1\n",
    "        \n",
    "        spans.append(doc.char_span(span_start, span_end))\n",
    "    return spans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.util import filter_spans\n",
    "def get_filtered_mentions(doc, phrase_mentions, mentions):\n",
    "    span_mentions = get_mention_spans(doc, mentions)\n",
    "    #phrase_mentions.extend(span_mentions)\n",
    "    filtered_matches = filter_spans(span_mentions)\n",
    "    return [{'start': doc[match.start].idx,'end': doc[match.end-1].idx + len(doc[match.end-1]), 'text':doc[match.start:match.end]} for match in filtered_matches if len(match) > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sylvia/.local/lib/python3.10/site-packages/transformers/pipelines/base.py:1157: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 189000 sentences\n",
      "processed 189500 sentences\n",
      "processed 190000 sentences\n",
      "processed 190500 sentences\n",
      "processed 191000 sentences\n",
      "processed 191500 sentences\n",
      "processed 192000 sentences\n",
      "processed 192500 sentences\n",
      "processed 193000 sentences\n",
      "processed 193500 sentences\n",
      "processed 194000 sentences\n",
      "processed 194500 sentences\n",
      "processed 195000 sentences\n",
      "processed 195500 sentences\n",
      "processed 196000 sentences\n",
      "processed 196500 sentences\n",
      "processed 197000 sentences\n",
      "processed 197500 sentences\n",
      "processed 198000 sentences\n",
      "processed 198500 sentences\n",
      "processed 199000 sentences\n",
      "processed 199500 sentences\n",
      "processed 200000 sentences\n",
      "processed 200500 sentences\n",
      "processed 201000 sentences\n",
      "processed 201500 sentences\n",
      "processed 202000 sentences\n",
      "processed 202500 sentences\n",
      "processed 203000 sentences\n",
      "processed 203500 sentences\n",
      "processed 204000 sentences\n",
      "processed 204500 sentences\n",
      "processed 205000 sentences\n",
      "processed 205500 sentences\n",
      "processed 206000 sentences\n",
      "processed 206500 sentences\n",
      "processed 207000 sentences\n",
      "processed 207500 sentences\n",
      "processed 208000 sentences\n",
      "processed 208500 sentences\n",
      "processed 209000 sentences\n",
      "processed 209500 sentences\n",
      "processed 210000 sentences\n",
      "processed 210500 sentences\n",
      "processed 211000 sentences\n",
      "processed 211500 sentences\n",
      "processed 212000 sentences\n",
      "processed 212500 sentences\n",
      "processed 213000 sentences\n",
      "processed 213500 sentences\n",
      "processed 214000 sentences\n",
      "processed 214500 sentences\n",
      "processed 215000 sentences\n",
      "processed 215500 sentences\n",
      "processed 216000 sentences\n",
      "processed 216500 sentences\n",
      "processed 217000 sentences\n",
      "processed 217500 sentences\n",
      "processed 218000 sentences\n",
      "processed 218500 sentences\n",
      "processed 219000 sentences\n",
      "processed 219500 sentences\n",
      "processed 220000 sentences\n",
      "processed 220500 sentences\n",
      "processed 221000 sentences\n",
      "processed 221500 sentences\n",
      "processed 222000 sentences\n",
      "processed 222500 sentences\n",
      "processed 223000 sentences\n",
      "processed 223500 sentences\n",
      "processed 224000 sentences\n",
      "processed 224500 sentences\n",
      "processed 225000 sentences\n",
      "processed 225500 sentences\n",
      "processed 226000 sentences\n",
      "processed 226500 sentences\n",
      "processed 227000 sentences\n",
      "processed 227500 sentences\n",
      "processed 228000 sentences\n",
      "processed 228500 sentences\n",
      "processed 229000 sentences\n",
      "processed 229500 sentences\n",
      "processed 230000 sentences\n",
      "processed 230500 sentences\n",
      "processed 231000 sentences\n",
      "processed 231500 sentences\n",
      "processed 232000 sentences\n",
      "processed 232500 sentences\n",
      "processed 233000 sentences\n",
      "processed 233500 sentences\n",
      "processed 234000 sentences\n",
      "processed 234500 sentences\n",
      "processed 235000 sentences\n",
      "processed 235500 sentences\n",
      "processed 236000 sentences\n",
      "processed 236500 sentences\n",
      "processed 237000 sentences\n",
      "processed 237500 sentences\n",
      "processed 238000 sentences\n",
      "processed 238500 sentences\n",
      "processed 239000 sentences\n",
      "processed 239500 sentences\n",
      "processed 240000 sentences\n",
      "processed 240500 sentences\n",
      "processed 241000 sentences\n",
      "processed 241500 sentences\n",
      "processed 242000 sentences\n",
      "processed 242500 sentences\n",
      "processed 243000 sentences\n",
      "processed 243500 sentences\n",
      "processed 244000 sentences\n",
      "processed 244500 sentences\n",
      "processed 245000 sentences\n",
      "processed 245500 sentences\n",
      "processed 246000 sentences\n",
      "processed 246500 sentences\n",
      "processed 247000 sentences\n",
      "processed 247500 sentences\n",
      "processed 248000 sentences\n",
      "processed 248500 sentences\n",
      "processed 249000 sentences\n",
      "processed 249500 sentences\n",
      "processed 250000 sentences\n",
      "processed 250500 sentences\n",
      "processed 251000 sentences\n",
      "processed 251500 sentences\n",
      "processed 252000 sentences\n",
      "processed 252500 sentences\n",
      "processed 253000 sentences\n",
      "processed 253500 sentences\n",
      "processed 254000 sentences\n",
      "processed 254500 sentences\n",
      "processed 255000 sentences\n",
      "processed 255500 sentences\n",
      "processed 256000 sentences\n",
      "processed 256500 sentences\n",
      "processed 257000 sentences\n",
      "processed 257500 sentences\n",
      "processed 258000 sentences\n",
      "processed 258500 sentences\n",
      "processed 259000 sentences\n",
      "processed 259500 sentences\n",
      "processed 260000 sentences\n",
      "processed 260500 sentences\n",
      "processed 261000 sentences\n",
      "processed 261500 sentences\n",
      "processed 262000 sentences\n",
      "processed 262500 sentences\n",
      "processed 263000 sentences\n",
      "processed 263500 sentences\n",
      "processed 264000 sentences\n",
      "processed 264500 sentences\n",
      "processed 265000 sentences\n",
      "processed 265500 sentences\n",
      "processed 266000 sentences\n",
      "processed 266500 sentences\n",
      "processed 267000 sentences\n",
      "processed 267500 sentences\n",
      "processed 268000 sentences\n",
      "processed 268500 sentences\n",
      "processed 269000 sentences\n",
      "processed 269500 sentences\n",
      "processed 270000 sentences\n",
      "processed 270500 sentences\n",
      "processed 271000 sentences\n",
      "processed 271500 sentences\n",
      "processed 272000 sentences\n",
      "processed 272500 sentences\n",
      "processed 273000 sentences\n",
      "processed 273500 sentences\n",
      "processed 274000 sentences\n",
      "processed 274500 sentences\n",
      "processed 275000 sentences\n",
      "processed 275500 sentences\n",
      "processed 276000 sentences\n",
      "processed 276500 sentences\n",
      "processed 277000 sentences\n",
      "processed 277500 sentences\n",
      "processed 278000 sentences\n",
      "processed 278500 sentences\n",
      "processed 279000 sentences\n",
      "processed 279500 sentences\n",
      "processed 280000 sentences\n",
      "processed 280500 sentences\n",
      "processed 281000 sentences\n",
      "processed 281500 sentences\n",
      "processed 282000 sentences\n",
      "processed 282500 sentences\n",
      "processed 283000 sentences\n",
      "processed 283500 sentences\n",
      "processed 284000 sentences\n",
      "processed 284500 sentences\n",
      "processed 285000 sentences\n",
      "processed 285500 sentences\n",
      "processed 286000 sentences\n",
      "processed 286500 sentences\n",
      "processed 287000 sentences\n",
      "processed 287500 sentences\n",
      "processed 288000 sentences\n",
      "processed 288500 sentences\n",
      "processed 289000 sentences\n",
      "processed 289500 sentences\n",
      "processed 290000 sentences\n",
      "processed 290500 sentences\n",
      "processed 291000 sentences\n",
      "processed 291500 sentences\n",
      "processed 292000 sentences\n",
      "processed 292500 sentences\n",
      "processed 293000 sentences\n",
      "processed 293500 sentences\n",
      "processed 294000 sentences\n",
      "processed 294500 sentences\n",
      "processed 295000 sentences\n",
      "processed 295500 sentences\n",
      "processed 296000 sentences\n",
      "processed 296500 sentences\n",
      "processed 297000 sentences\n",
      "processed 297500 sentences\n",
      "processed 298000 sentences\n",
      "processed 298500 sentences\n",
      "processed 299000 sentences\n",
      "processed 299500 sentences\n",
      "processed 300000 sentences\n",
      "processed 300500 sentences\n",
      "processed 301000 sentences\n",
      "processed 301500 sentences\n",
      "processed 302000 sentences\n",
      "processed 302500 sentences\n",
      "processed 303000 sentences\n",
      "processed 303500 sentences\n",
      "processed 304000 sentences\n",
      "processed 304500 sentences\n",
      "processed 305000 sentences\n",
      "processed 305500 sentences\n",
      "processed 306000 sentences\n",
      "processed 306500 sentences\n",
      "processed 307000 sentences\n",
      "processed 307500 sentences\n",
      "processed 308000 sentences\n",
      "processed 308500 sentences\n",
      "processed 309000 sentences\n",
      "processed 309500 sentences\n",
      "processed 310000 sentences\n",
      "processed 310500 sentences\n",
      "processed 311000 sentences\n",
      "processed 311500 sentences\n",
      "processed 312000 sentences\n",
      "processed 312500 sentences\n",
      "processed 313000 sentences\n",
      "processed 313500 sentences\n",
      "processed 314000 sentences\n",
      "processed 314500 sentences\n",
      "processed 315000 sentences\n",
      "processed 315500 sentences\n",
      "processed 316000 sentences\n",
      "processed 316500 sentences\n",
      "processed 317000 sentences\n",
      "processed 317500 sentences\n",
      "processed 318000 sentences\n",
      "processed 318500 sentences\n",
      "processed 319000 sentences\n",
      "processed 319500 sentences\n",
      "processed 320000 sentences\n",
      "processed 320500 sentences\n",
      "processed 321000 sentences\n",
      "processed 321500 sentences\n",
      "processed 322000 sentences\n",
      "processed 322500 sentences\n",
      "processed 323000 sentences\n",
      "processed 323500 sentences\n",
      "processed 324000 sentences\n",
      "processed 324500 sentences\n",
      "processed 325000 sentences\n",
      "processed 325500 sentences\n",
      "processed 326000 sentences\n",
      "processed 326500 sentences\n",
      "processed 327000 sentences\n",
      "processed 327500 sentences\n",
      "processed 328000 sentences\n",
      "processed 328500 sentences\n",
      "processed 329000 sentences\n",
      "processed 329500 sentences\n",
      "processed 330000 sentences\n",
      "processed 330500 sentences\n",
      "processed 331000 sentences\n",
      "processed 331500 sentences\n",
      "processed 332000 sentences\n",
      "processed 332500 sentences\n",
      "processed 333000 sentences\n",
      "processed 333500 sentences\n",
      "processed 334000 sentences\n",
      "processed 334500 sentences\n",
      "processed 335000 sentences\n",
      "processed 335500 sentences\n",
      "processed 336000 sentences\n",
      "processed 336500 sentences\n",
      "processed 337000 sentences\n",
      "processed 337500 sentences\n",
      "processed 338000 sentences\n",
      "processed 338500 sentences\n",
      "processed 339000 sentences\n",
      "processed 339500 sentences\n",
      "processed 340000 sentences\n",
      "processed 340500 sentences\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 341000 sentences\n",
      "processed 341500 sentences\n",
      "processed 342000 sentences\n",
      "processed 342500 sentences\n",
      "processed 343000 sentences\n",
      "processed 343500 sentences\n",
      "processed 344000 sentences\n",
      "processed 344500 sentences\n",
      "processed 345000 sentences\n",
      "processed 345500 sentences\n",
      "processed 346000 sentences\n",
      "processed 346500 sentences\n",
      "processed 347000 sentences\n",
      "processed 347500 sentences\n",
      "processed 348000 sentences\n",
      "processed 348500 sentences\n",
      "processed 349000 sentences\n",
      "processed 349500 sentences\n",
      "processed 350000 sentences\n",
      "processed 350500 sentences\n",
      "processed 351000 sentences\n",
      "processed 351500 sentences\n",
      "processed 352000 sentences\n",
      "processed 352500 sentences\n",
      "processed 353000 sentences\n",
      "processed 353500 sentences\n",
      "processed 354000 sentences\n",
      "processed 354500 sentences\n",
      "processed 355000 sentences\n",
      "processed 355500 sentences\n",
      "processed 356000 sentences\n",
      "processed 356500 sentences\n",
      "processed 357000 sentences\n",
      "processed 357500 sentences\n",
      "processed 358000 sentences\n",
      "processed 358500 sentences\n",
      "processed 359000 sentences\n",
      "processed 359500 sentences\n",
      "processed 360000 sentences\n",
      "processed 360500 sentences\n",
      "processed 361000 sentences\n",
      "processed 361500 sentences\n",
      "processed 362000 sentences\n",
      "processed 362500 sentences\n",
      "processed 363000 sentences\n",
      "processed 363500 sentences\n",
      "processed 364000 sentences\n",
      "processed 364500 sentences\n",
      "processed 365000 sentences\n",
      "processed 365500 sentences\n",
      "processed 366000 sentences\n",
      "processed 366500 sentences\n",
      "processed 367000 sentences\n",
      "processed 367500 sentences\n",
      "processed 368000 sentences\n",
      "processed 368500 sentences\n",
      "processed 369000 sentences\n",
      "processed 369500 sentences\n",
      "processed 370000 sentences\n",
      "processed 370500 sentences\n",
      "processed 371000 sentences\n",
      "processed 371500 sentences\n",
      "processed 372000 sentences\n",
      "processed 372500 sentences\n",
      "processed 373000 sentences\n",
      "processed 373500 sentences\n",
      "processed 374000 sentences\n",
      "processed 374500 sentences\n",
      "processed 375000 sentences\n",
      "processed 375500 sentences\n",
      "processed 376000 sentences\n",
      "processed 376500 sentences\n",
      "processed 377000 sentences\n",
      "processed 377500 sentences\n",
      "processed 378000 sentences\n",
      "processed 378500 sentences\n",
      "processed 379000 sentences\n",
      "processed 379500 sentences\n",
      "processed 380000 sentences\n",
      "processed 380500 sentences\n",
      "processed 381000 sentences\n",
      "processed 381500 sentences\n",
      "processed 382000 sentences\n",
      "processed 382500 sentences\n",
      "processed 383000 sentences\n",
      "processed 383500 sentences\n",
      "processed 384000 sentences\n",
      "processed 384500 sentences\n",
      "processed 385000 sentences\n",
      "processed 385500 sentences\n",
      "processed 386000 sentences\n"
     ]
    }
   ],
   "source": [
    "original_mentions_list = []\n",
    "for index, row in df_dev_sentences[df_dev_sentences['lang']==lang].iterrows():\n",
    "    text = row['text'].rstrip()\n",
    "    tokenized_sentence, original_token_offsets = tokenize(text)\n",
    "    #doc = nlp(tokenized_sentence)\n",
    "    #phrase_mentions = get_phrase_mentions(doc)\n",
    "    filtered_mentions = get_mentions(tokenized_sentence)\n",
    "    \n",
    "    #filtered_mentions = get_filtered_mentions(doc, phrase_mentions, mentions)\n",
    "    \n",
    "    original_mentions = get_original_mention_offset(filtered_mentions, tokenized_sentence, original_token_offsets, text, row['filename'], row['batch_start'])\n",
    "    original_mentions_list.extend(original_mentions)\n",
    "    \n",
    "    if (index+1) % 500 == 0:\n",
    "        print(f'processed {index+1} sentences')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>start_span</th>\n",
       "      <th>end_span</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>multicardioner_test+bg_100</td>\n",
       "      <td>792</td>\n",
       "      <td>799</td>\n",
       "      <td>oxÃ­geno</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>multicardioner_test+bg_100</td>\n",
       "      <td>850</td>\n",
       "      <td>857</td>\n",
       "      <td>oxÃ­geno</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>multicardioner_test+bg_100</td>\n",
       "      <td>1191</td>\n",
       "      <td>1200</td>\n",
       "      <td>fentanilo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>multicardioner_test+bg_100</td>\n",
       "      <td>1719</td>\n",
       "      <td>1728</td>\n",
       "      <td>midazolam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>multicardioner_test+bg_100</td>\n",
       "      <td>1738</td>\n",
       "      <td>1745</td>\n",
       "      <td>morfina</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     filename  start_span  end_span       text\n",
       "0  multicardioner_test+bg_100         792       799    oxÃ­geno\n",
       "1  multicardioner_test+bg_100         850       857    oxÃ­geno\n",
       "2  multicardioner_test+bg_100        1191      1200  fentanilo\n",
       "3  multicardioner_test+bg_100        1719      1728  midazolam\n",
       "4  multicardioner_test+bg_100        1738      1745    morfina"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mentions = pd.DataFrame.from_records(original_mentions_list)\n",
    "df_mentions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mentions['label'] = target_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mentions[['filename', 'label', 'start_span', 'end_span', 'text']].to_csv(result_file, sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# w/ and w/o filtering\n",
    "# es - |0.8636|0.9028|0.8827 || |0.8479|0.9104|0.878\n",
    "# en - |0.8507|0.8924|0.8711 || |0.832|0.898|0.8638\n",
    "# it - |0.8606|0.8789|0.8697 || |0.8414|0.8925|0.8662"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
